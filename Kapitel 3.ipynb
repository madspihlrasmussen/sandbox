{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad667df",
   "metadata": {},
   "source": [
    "# Derivata\n",
    "\n",
    "Vi vill kunna evaluera derivatan av en funktion $f(x)$ i en given punkt $f'(x)$. Detta är mer eller mindre trivialt när vi har en känd analytisk funktion $f$ eftersom denn kan deriveras och evalueras direkt. Men i många fall har vi bara en datamängd i form av diskreta punkter $(x_1, f(x_1)), (x_2, f(x_2)), ..., (x_n, f(x_n))$ från vilken vi måste försöka att lösa vårt problem. \n",
    "\n",
    "En typisk metod är att anpassa en kurva till data och försöka sig på anlaytisk differentiering därifrån. Detta är en möjlighet, men en kurva som verkar passa med data behöver inte motsvara att den antagna funktionens derivata är en bra approximation till data och vi kan hamna i en situation med ett betydligt fel som bl.a. kan bero på att vi egentligen inte vet om analytiska formen är korrekt eller bara en till synes fungerande approximation.\n",
    "\n",
    "Vi använder därför i regeln finita differens metoder istället vilket innebär att vi utför en numerisk differentiering. Med denna metod utgår vi från en Taylorexpansion av en förmodat analytisk funktion som vi menar bör fungera i ett område runt en given punkt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7fa8c",
   "metadata": {},
   "source": [
    "## Analytisk differentiering\n",
    "\n",
    "Det grundläggande uttrycket för en funktions derivata tar vi som\n",
    "\n",
    "\\begin{align}\\label{analytisk_derivata}\n",
    "    \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n",
    "\\end{align}\n",
    "\n",
    "men i praktiken utnyttjar vi kända tekniker som har utvecklats för den grundläggande gränsvärdesdefinitionen för att direkt evaluera exponentialfunktioner, polynomfunktioner, logaritmer, potensfunktioner, trigonometriska funktioner och så vidare.\n",
    "\n",
    "I Python kan vi evaluera analytiska uttryck med $\\texttt{SymPy}$ biblioteket. \n",
    "\n",
    "\n",
    "## Finita differenser\n",
    "\n",
    "Om vi nu evaluerar (\\ref{analytisk_derivata}) för en approximation $\\tilde{x}$ får vi\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{df}{dx} \\biggr\\vert_{\\tilde{x}} = \\lim_{h \\to} \\frac{f(\\tilde{x}+h) - f(\\tilde{x})}{h}\n",
    "\\end{align}\n",
    "\n",
    "I praktiken gör vi ingen skillnad på $x$ och $\\tilde{x}$ så nedan fortsätter vi med $\\tilde{x}=x$ överallt.\n",
    "\n",
    "### Framåtdifferenser och bakåtdifferenser\n",
    "\n",
    "Låt nu $x_0=x$ i en Taylorexpansion av $f(x+h)$. Vi expanderar alltså runt $x$ således att\n",
    "\n",
    "$$\n",
    "    f(x+h) = f(x_0) + (x+h-x_0)f'(x) + \\frac{1}{2}(x+h-x_0)^2f''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "eftersom funktionens variabel är $x+h$ överallt istället för där vi kanska är vana att bara skriva $x$ medan punkten vi expanderar i många andra fall kanske har varit antingen 0 (Maclaurinexpansion) eller runt någon godtycklig punkt $a$. Saken är här att vi har ett *litet* värde $h$ och vi expanderar runt det $x$ (alltså $x_0=x$) som ligger på ett litet avstånd av $x+h$ för vilket vi evaluerar funktionen. \n",
    "\n",
    "\n",
    "Men $x_0=x$ så vi kan skriva om detta till\n",
    "\n",
    "$$\n",
    "    f(x+h) = f(x) + hf'(x) + \\frac{1}{2}h^2f''(x) + \\frac{1}{6}h^3f^{(3)}(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Vi antar nu att termer med $h^2$ eller större ordning på $h$ är försumbara. I första han kan vi skriva om uttrycket genom att subtrahera $f(x)$ i båda leden och sedan dela igenom med $h$ överallt. När vi har gjort det samlar vi alla högre ordningens termer i $\\mathcal{O}$:\n",
    "\n",
    "$$\n",
    "    \\frac{f(x+h)-f(x)}{h} = f'(x) + \\frac{h}{2}f''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Detta ger oss slutligen *första framåtdifferens approximationen*:\n",
    "\n",
    "$$\n",
    "    f'(x) = \\frac{f(x+h)-f(x)}{h} - \\frac{h}{2}f''(x) + \\cdots     \n",
    "$$\n",
    "\n",
    "eller\n",
    "\n",
    "\\begin{align}\\label{framåtdifferens}\n",
    "    f'(x) = \\frac{f(x+h)-f(x)}{h} + \\mathcal{O}(h) \n",
    "\\end{align}\n",
    "\n",
    "där vi i praktiken bortser från $\\mathcal{O}$-funktionen (*ordo*) och endast beräknar differenskvoten, men nu *som* kvot och inte som ett gränsvärde. Ordofunktionen ger samtidigt ett mått på storleksordningen $h$ av felet. Och när vi låter $h$ vara litet får vi också mycket mindre fel för till exempel termer av ordning $h^6$ än vi gör för termer av till exempel ordning $h$. Felet minskar med andra ord snabbt för högre ordningar, men det kan vara stort för lägre ordningar. \n",
    "\n",
    "Vi kallar det en framåtdifferens eftersom vi börjar i $x$ och tar ett litet steg fram av storleken $h$ och sen evaluerar vi differensen mellan dessa två punkter. Kvoten är således helt enkelt ett uttryck för lutningen på grafen till den funktion som vi antar ligger bakom punktmängden och från vilken vi gjorde Taylorexpansionen (utan att känna till funktionens analytiska form). \n",
    "\n",
    "Expanderar vi nu helt analogt $f(x-h)$ får vi\n",
    "$$\n",
    "    f(x-h) = f(x) + (x-h-x)f'(x) + \\frac{1}{2}(x-h-x)^2f''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "eller \n",
    "\n",
    "$$\n",
    "    f(x-h)-f(x) = -hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f^{(3)}(x) + \\cdots\n",
    "$$\n",
    "\n",
    "och därför *första bakåtdifferens approximationen*:\n",
    "\n",
    "\\begin{align}\\label{bakåtdifferens}\n",
    "    f'(x) = \\frac{f(x)-f(x-h)}{h} + \\mathcal{O}(h) \n",
    "\\end{align}\n",
    "\n",
    "### Felanalys för framåtdifferensen\n",
    "\n",
    "För att minska felet i approximationen av derivatan med en finit differenskvot kan vi göra $h$ litet, men råkar vi göra $h$ *för* litet kan vi få problemet att vi får avrundningsfel som sen bidrar till att öka slutliga felet. \n",
    "\n",
    "Vi har med andra ord ett trunkeringsfel $\\mathcal{E}_{app}$ från Taylorexpansionens approximation och ett avrundningsfel $\\mathcal{E}_{avr}$ som uppkommer när vi utför finita differenskvotens subtraktion och division. Båda dessa felen är absoluta fel och approximationsfelet kan vi direkt se från Taylorexpansionen som\n",
    "\n",
    "\\begin{align}\\label{trunkeringsfel}\n",
    "    \\mathcal{E}_{app} = \\frac{h}{2}\\left| f''(x) \\right|\n",
    "\\end{align}\n",
    "\n",
    "Mera formellt tas felet egentligen i en punkt $\\xi$ mellan $x$ och $x+h$ men eftersom $h$ antas vara litet är det acceptabelt att låta felevalueringen ske med avseende på $x$ när $\\left|f''(\\xi)\\right| \\approx \\left|f''(x)\\right|$. En sådan approximation kommer vi i allmänhet att använda.\n",
    "\n",
    "I approximationen av felet från avrundningen utgår vi från finita differenskvotens täljare där vi har ett maximalt absolut fel $\\Delta f$ som motsvarar summan av termernas absolutvärden i differensen $f(x+h)-f(x)$, alltså maximala felet $\\Delta f = |\\Delta f(x+h)| + |\\Delta f(x)|$.\n",
    "\n",
    "Låt nu $f(x+h)\\approx f(x)$ så $\\Delta f \\approx 2f(x)$. På något sätt får Gezerlis detta att hänga ihop med maskinprecisionen $\\epsilon$ således att avrundningsfelet blir absoluta felet dividerat med $h$ från differenskvoten:\n",
    "\n",
    "\\begin{align}\\label{avrundningsfel}\n",
    "    \\mathcal{E}_{avr} = \\frac{2|f(x)|\\epsilon}{h}\n",
    "\\end{align}\n",
    "\n",
    "Avrundningsfelet växer alltså när vi minskar $h$ medan trunkeringsfelet avtar när $h$ minskar. \n",
    "\n",
    "Totala felet blir\n",
    "\n",
    "$$\n",
    "    \\mathcal{E} = \\frac{h}{2}\\left| f''(x) \\right| + \\frac{2|f(x)|\\epsilon}{h}\n",
    "$$\n",
    "\n",
    "Betrakta detta som en felfunktion i $h$ som vi kan optimera genom att söka det optimala värde på $h=h_{opt}$ för vilket derivatan av felfunktionen blir noll:\n",
    "\n",
    "$$\n",
    "    \\frac{d\\mathcal{E}}{dh} = \\frac{1}{2}\\left| f''(x) \\right| - \\frac{2|f(x)|\\epsilon}{h^2} = 0\n",
    "$$\n",
    "\n",
    "och med $h=h_{opt}$ alltså\n",
    "\n",
    "\\begin{align}\\label{optimal_h_ekvation}\n",
    "    \\frac{h_{opt}}{2}\\left| f''(x) \\right| = \\frac{2|f(x)|\\epsilon}{h_{opt}}\n",
    "\\end{align}\n",
    "\n",
    "eller specifikt med avseende på $h_{opt}$:\n",
    "\n",
    "\\begin{align}\\label{optimalt_h}\n",
    "    h_{opt} = \\sqrt{4\\epsilon\\left|\\frac{f(x)}{f''(x)}\\right|}\n",
    "\\end{align}\n",
    "\n",
    "Använd nu (\\ref{optimalt_h}) i uttrycket för totala felet tillsammans med (\\ref{optimal_h_ekvation}) så vi får\n",
    "\n",
    "$$\n",
    "    \\mathcal{E}_{opt} = \\frac{h_{opt}}{2}\\left| f''(x) \\right| + \\frac{h_{opt}}{2}\\left| f''(x) \\right| = |f''(x]|h_{opt}\n",
    "$$\n",
    "\n",
    "och alltså\n",
    "\n",
    "$$\n",
    "    \\mathcal{E}_{opt} = |f''(x)|\\sqrt{4\\epsilon\\left|\\frac{f(x)}{f''(x)}\\right|}\n",
    "$$\n",
    "\n",
    "och slutligen\n",
    "\n",
    "\\begin{align}\\label{optimalt_fel}\n",
    "    \\mathcal{E}_{opt} = \\sqrt{4\\epsilon|f''(x)f(x)|}\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
